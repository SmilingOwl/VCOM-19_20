{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPPIs6UBQ3mF"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m33Xj2eoQ3n_"
   },
   "outputs": [],
   "source": [
    "import random as rn\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
    "                              inter_op_parallelism_threads=1)\n",
    "tf.random.set_seed(1234)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "G72kZ6BxQ3qS",
    "outputId": "ce6a6ec6-42df-40fe-f965-40e75b144ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f086caf1f28> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0869348c88> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0869348cf8> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f086a9a8668> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086caf1b38> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0869a36ba8> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f086cb41a20> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086caaa400> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086cb03c50> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086cae7ef0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f086c860f28> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086caa5c88> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086a755c18> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086c890668> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f086a755278> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086c890c50> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0869a3e470> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f086c840860> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f086c819898> False\n"
     ]
    }
   ],
   "source": [
    "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in vgg_conv.layers:\n",
    "    layer.trainable = False \n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEAKQ7YoQ3sd"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "  \n",
    "  headModel = vgg_conv.output\n",
    "  headModel = keras.layers.Flatten(name=\"flatten\")(headModel)\n",
    "  headModel = keras.layers.Dense(512, activation=\"relu\")(headModel)\n",
    "  headModel = keras.layers.Dropout(0.5)(headModel)\n",
    "  headModel = keras.layers.Dense(7, activation=\"softmax\")(headModel)\n",
    "\n",
    "  model = Model(inputs=vgg_conv.input, outputs=headModel)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "      loss=keras.losses.categorical_crossentropy,\n",
    "      metrics=['accuracy'])\n",
    "  \n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "colab_type": "code",
    "id": "lXM-U_u6Q3u8",
    "outputId": "4ca52815-e8ca-4ac5-bb05-317d1ba11fc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 27,563,847\n",
      "Trainable params: 12,849,159\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "#model.save_weights('initial_vgg16_1fc_512_head.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OoCm2hy6hls4",
    "outputId": "b60230d3-4139-4b76-87b2-83f1f0f97ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have\n",
      "I have\n"
     ]
    }
   ],
   "source": [
    "# adding regularization\n",
    "regularizer = tf.keras.regularizers.l2(5e-4)\n",
    "\n",
    "for layer in model.layers:\n",
    "    for attr in ['kernel_regularizer']:\n",
    "        if hasattr(layer, attr):\n",
    "          print(\"I have\")\n",
    "          setattr(layer, attr, regularizer)\n",
    "\n",
    "model_json = model.to_json()\n",
    "model = tf.keras.models.model_from_json(model_json)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-4),\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Reload the model weights\n",
    "model.load_weights('/content/drive/My Drive/VCOM/Task2/tuning2_1fc128_head_021.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZJ2UnplP5b7Q",
    "outputId": "00121ed2-e1c3-4aae-f2f2-c7c9a567f0bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(model.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "3DuzZJywQ3w5",
    "outputId": "505baa0d-9fe4-47a0-9733-3bcb4a66e75c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6506 images belonging to 7 classes.\n",
      "Found 1504 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      preprocessing_function=preprocess_input,\n",
    "      rotation_range=10,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      #shear_range=0.1,\n",
    "      zoom_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      vertical_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_batchsize = 128\n",
    "val_batchsize = 32\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=\"/content/Dataset/train\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=train_batchsize, \n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        directory=\"/content/Dataset/valid\",\n",
    "        target_size=(224, 224),\n",
    "        batch_size=val_batchsize,\n",
    "        shuffle=False, \n",
    "        seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "rsg5NOBWQ3zB",
    "outputId": "e674b54f-f776-46b5-db7f-0467c6dc47ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.384097035040432\n",
      "2.782720273738238\n",
      "1.30172068827531\n",
      "12.55984555984556\n",
      "1.2855166963050781\n",
      "0.2132695207500164\n",
      "10.213500784929357\n"
     ]
    }
   ],
   "source": [
    "akiec = 212\n",
    "bcc = 334\n",
    "bkl = 714\n",
    "df = 74\n",
    "mel = 723\n",
    "nv = 4358\n",
    "vasc = 91\n",
    "\n",
    "total = 6506\n",
    "# Scaling by total/7 helps keep the loss to a similar magnitude.\n",
    "weight_for_0 = (1 / akiec) * (total)/7.0 \n",
    "weight_for_1 = (1 / bcc) * (total)/7.0\n",
    "weight_for_2 = (1 / bkl) * (total)/7.0 \n",
    "weight_for_3 = (1 / df) * (total)/7.0\n",
    "weight_for_4 = (1 / mel) * (total)/7.0 \n",
    "weight_for_5 = (1 / nv) * (total)/7.0\n",
    "weight_for_6 = (1 / vasc) * (total)/7.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2, 3: weight_for_3, 4: weight_for_4,\n",
    "                5: weight_for_5, 6: weight_for_6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "QvS8GkHuLCnw",
    "outputId": "c123108d-2555-443e-88f5-8bbcac4ec403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f0865f774e0> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f77a90> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f77c88> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0865f7dba8> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f7da20> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f81b38> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0865f88400> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f13d30> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f13e48> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f17860> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0865f20588> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f2a470> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f2f3c8> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f38588> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0865f3d4a8> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f3d320> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f43668> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f0865f4e828> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f0867216748> True\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x7f0867239dd8> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f0867239f98> True\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x7f0865f771d0> True\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7f08672395f8> True\n"
     ]
    }
   ],
   "source": [
    "# Optional Finetuning\n",
    "\n",
    "#model.load_weights('/content/tuning2_1fc512_head_038.h5')\n",
    "for layer in vgg_conv.layers:\n",
    "    layer.trainable = True \n",
    "for layer2 in model.layers:\n",
    "    print(layer2, layer2.trainable)\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=1e-6)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IcHtj8xVQ328",
    "outputId": "96be4280-bf8d-4602-9441-edd9fa26d2fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 2.0167 - accuracy: 0.4021\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.43816, saving model to grafico_1fc512_001.h5\n",
      "51/51 [==============================] - 170s 3s/step - loss: 2.0167 - accuracy: 0.4021 - val_loss: 1.5340 - val_accuracy: 0.4382\n",
      "Epoch 2/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.6149 - accuracy: 0.4164\n",
      "Epoch 00002: val_accuracy improved from 0.43816 to 0.48404, saving model to grafico_1fc512_002.h5\n",
      "51/51 [==============================] - 170s 3s/step - loss: 1.6149 - accuracy: 0.4164 - val_loss: 1.3444 - val_accuracy: 0.4840\n",
      "Epoch 3/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.5135 - accuracy: 0.4460\n",
      "Epoch 00003: val_accuracy improved from 0.48404 to 0.52194, saving model to grafico_1fc512_003.h5\n",
      "51/51 [==============================] - 169s 3s/step - loss: 1.5135 - accuracy: 0.4460 - val_loss: 1.3334 - val_accuracy: 0.5219\n",
      "Epoch 4/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.4493 - accuracy: 0.4972\n",
      "Epoch 00004: val_accuracy improved from 0.52194 to 0.53191, saving model to grafico_1fc512_004.h5\n",
      "51/51 [==============================] - 170s 3s/step - loss: 1.4493 - accuracy: 0.4972 - val_loss: 1.2382 - val_accuracy: 0.5319\n",
      "Epoch 5/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.3407 - accuracy: 0.5038\n",
      "Epoch 00005: val_accuracy improved from 0.53191 to 0.55918, saving model to grafico_1fc512_005.h5\n",
      "51/51 [==============================] - 169s 3s/step - loss: 1.3407 - accuracy: 0.5038 - val_loss: 1.1902 - val_accuracy: 0.5592\n",
      "Epoch 6/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.2895 - accuracy: 0.5231\n",
      "Epoch 00006: val_accuracy improved from 0.55918 to 0.61835, saving model to grafico_1fc512_006.h5\n",
      "51/51 [==============================] - 169s 3s/step - loss: 1.2895 - accuracy: 0.5231 - val_loss: 1.0739 - val_accuracy: 0.6184\n",
      "Epoch 7/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.2270 - accuracy: 0.5223\n",
      "Epoch 00007: val_accuracy improved from 0.61835 to 0.62234, saving model to grafico_1fc512_007.h5\n",
      "51/51 [==============================] - 169s 3s/step - loss: 1.2270 - accuracy: 0.5223 - val_loss: 0.9983 - val_accuracy: 0.6223\n",
      "Epoch 8/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.2109 - accuracy: 0.5369\n",
      "Epoch 00008: val_accuracy did not improve from 0.62234\n",
      "51/51 [==============================] - 170s 3s/step - loss: 1.2109 - accuracy: 0.5369 - val_loss: 1.1082 - val_accuracy: 0.5918\n",
      "Epoch 9/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.1374 - accuracy: 0.5530\n",
      "Epoch 00009: val_accuracy did not improve from 0.62234\n",
      "51/51 [==============================] - 170s 3s/step - loss: 1.1374 - accuracy: 0.5530 - val_loss: 1.1609 - val_accuracy: 0.5625\n",
      "Epoch 10/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.1051 - accuracy: 0.5686\n",
      "Epoch 00010: val_accuracy did not improve from 0.62234\n",
      "51/51 [==============================] - 170s 3s/step - loss: 1.1051 - accuracy: 0.5686 - val_loss: 1.0544 - val_accuracy: 0.6011\n",
      "Epoch 11/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.0670 - accuracy: 0.5758\n",
      "Epoch 00011: val_accuracy did not improve from 0.62234\n",
      "51/51 [==============================] - 170s 3s/step - loss: 1.0670 - accuracy: 0.5758 - val_loss: 1.0103 - val_accuracy: 0.6190\n",
      "Epoch 12/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.0430 - accuracy: 0.5872\n",
      "Epoch 00012: val_accuracy improved from 0.62234 to 0.66622, saving model to grafico_1fc512_012.h5\n",
      "51/51 [==============================] - 170s 3s/step - loss: 1.0430 - accuracy: 0.5872 - val_loss: 0.9350 - val_accuracy: 0.6662\n",
      "Epoch 13/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 1.0154 - accuracy: 0.6114\n",
      "Epoch 00013: val_accuracy did not improve from 0.66622\n",
      "51/51 [==============================] - 169s 3s/step - loss: 1.0154 - accuracy: 0.6114 - val_loss: 0.9760 - val_accuracy: 0.6350\n",
      "Epoch 14/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9432 - accuracy: 0.6034\n",
      "Epoch 00014: val_accuracy did not improve from 0.66622\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.9432 - accuracy: 0.6034 - val_loss: 1.0806 - val_accuracy: 0.6017\n",
      "Epoch 15/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9788 - accuracy: 0.6139\n",
      "Epoch 00015: val_accuracy did not improve from 0.66622\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.9788 - accuracy: 0.6139 - val_loss: 0.9700 - val_accuracy: 0.6250\n",
      "Epoch 16/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9601 - accuracy: 0.6111\n",
      "Epoch 00016: val_accuracy did not improve from 0.66622\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.9601 - accuracy: 0.6111 - val_loss: 0.9934 - val_accuracy: 0.6303\n",
      "Epoch 17/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9222 - accuracy: 0.6025\n",
      "Epoch 00017: val_accuracy did not improve from 0.66622\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.9222 - accuracy: 0.6025 - val_loss: 0.9655 - val_accuracy: 0.6150\n",
      "Epoch 18/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8870 - accuracy: 0.6136\n",
      "Epoch 00018: val_accuracy did not improve from 0.66622\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.8870 - accuracy: 0.6136 - val_loss: 0.9212 - val_accuracy: 0.6489\n",
      "Epoch 19/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8868 - accuracy: 0.6314\n",
      "Epoch 00019: val_accuracy improved from 0.66622 to 0.67221, saving model to grafico_1fc512_019.h5\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.8868 - accuracy: 0.6314 - val_loss: 0.8777 - val_accuracy: 0.6722\n",
      "Epoch 20/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.9171 - accuracy: 0.6297\n",
      "Epoch 00020: val_accuracy did not improve from 0.67221\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.9171 - accuracy: 0.6297 - val_loss: 0.9458 - val_accuracy: 0.6456\n",
      "Epoch 21/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8921 - accuracy: 0.6260\n",
      "Epoch 00021: val_accuracy did not improve from 0.67221\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.8921 - accuracy: 0.6260 - val_loss: 1.0133 - val_accuracy: 0.6210\n",
      "Epoch 22/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8416 - accuracy: 0.6242\n",
      "Epoch 00022: val_accuracy did not improve from 0.67221\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.8416 - accuracy: 0.6242 - val_loss: 0.9921 - val_accuracy: 0.6330\n",
      "Epoch 23/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8206 - accuracy: 0.6417\n",
      "Epoch 00023: val_accuracy did not improve from 0.67221\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.8206 - accuracy: 0.6417 - val_loss: 0.9266 - val_accuracy: 0.6483\n",
      "Epoch 24/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.8165 - accuracy: 0.6517\n",
      "Epoch 00024: val_accuracy did not improve from 0.67221\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.8165 - accuracy: 0.6517 - val_loss: 0.9258 - val_accuracy: 0.6436\n",
      "Epoch 25/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7969 - accuracy: 0.6503\n",
      "Epoch 00025: val_accuracy did not improve from 0.67221\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.7969 - accuracy: 0.6503 - val_loss: 0.9559 - val_accuracy: 0.6463\n",
      "Epoch 26/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7607 - accuracy: 0.6512\n",
      "Epoch 00026: val_accuracy improved from 0.67221 to 0.69282, saving model to grafico_1fc512_026.h5\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.7607 - accuracy: 0.6512 - val_loss: 0.8495 - val_accuracy: 0.6928\n",
      "Epoch 27/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7438 - accuracy: 0.6749\n",
      "Epoch 00027: val_accuracy improved from 0.69282 to 0.69348, saving model to grafico_1fc512_027.h5\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.7438 - accuracy: 0.6749 - val_loss: 0.8367 - val_accuracy: 0.6935\n",
      "Epoch 28/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7323 - accuracy: 0.6611\n",
      "Epoch 00028: val_accuracy did not improve from 0.69348\n",
      "51/51 [==============================] - 170s 3s/step - loss: 0.7323 - accuracy: 0.6611 - val_loss: 0.8750 - val_accuracy: 0.6795\n",
      "Epoch 29/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7893 - accuracy: 0.6642\n",
      "Epoch 00029: val_accuracy did not improve from 0.69348\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.7893 - accuracy: 0.6642 - val_loss: 0.9321 - val_accuracy: 0.6682\n",
      "Epoch 30/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7364 - accuracy: 0.6755\n",
      "Epoch 00030: val_accuracy did not improve from 0.69348\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.7364 - accuracy: 0.6755 - val_loss: 0.9317 - val_accuracy: 0.6715\n",
      "Epoch 31/100\n",
      "51/51 [==============================] - ETA: 0s - loss: 0.7009 - accuracy: 0.6721\n",
      "Epoch 00031: val_accuracy did not improve from 0.69348\n",
      "51/51 [==============================] - 169s 3s/step - loss: 0.7009 - accuracy: 0.6721 - val_loss: 0.9187 - val_accuracy: 0.6669\n",
      "Epoch 32/100\n",
      "16/51 [========>.....................] - ETA: 1:37 - loss: 0.6834 - accuracy: 0.6753"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = load_model('/content/grafico_1fc512_001.h5')\n",
    "#model.load_weights()\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('vgg16_1fc512_{epoch:03d}.h5', monitor='val_accuracy', verbose=1, save_best_only=True,  mode='max', save_freq='epoch')\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, verbose=1, mode='min')\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      epochs=100,\n",
    "      class_weight=class_weight,\n",
    "      validation_data=validation_generator,\n",
    "      callbacks=[checkpoint,early],\n",
    "      verbose=1, \n",
    "      use_multiprocessing=False,\n",
    "      max_queue_size=10,                # maximum size for the generator queue\n",
    "      workers=1,  \n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PB9YOhITQ35H"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "sSdH7K0ZSUC-",
    "outputId": "79c9785f-bc73-4a86-9b42-a013701b5d47",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2005 images belonging to 7 classes.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       AKIEC       0.67      0.47      0.55        66\n",
      "         BCC       0.76      0.79      0.78       103\n",
      "         BKL       0.51      0.71      0.60       220\n",
      "          DF       0.52      0.61      0.56        23\n",
      "         MEL       0.40      0.64      0.49       223\n",
      "          NV       0.94      0.79      0.86      1341\n",
      "        VASC       0.71      0.86      0.78        29\n",
      "\n",
      "    accuracy                           0.75      2005\n",
      "   macro avg       0.65      0.69      0.66      2005\n",
      "weighted avg       0.80      0.75      0.77      2005\n",
      "\n",
      "[[  31    4   20    2    8    1    0]\n",
      " [   2   81   10    2    4    4    0]\n",
      " [   5    7  156    2   30   20    0]\n",
      " [   2    1    3   14    0    3    0]\n",
      " [   4    2   26    0  142   45    4]\n",
      " [   2    9   87    7  172 1058    6]\n",
      " [   0    2    1    0    1    0   25]]\n",
      "[0.7410634756088257, 0.7446383833885193]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "tsdata = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = tsdata.flow_from_directory(directory=\"/content/Dataset/test\", target_size=(224,224), shuffle=False, batch_size=1, seed=42)\n",
    "\n",
    "#model = load_model('test0002.h5')\n",
    "model.load_weights('/content/finetuning3_1fc512_all_027.h5')\n",
    "\n",
    "results = model.evaluate(test_generator)\n",
    "print(results)\n",
    "test_generator.reset()\n",
    "predIdxs = model.predict(test_generator)\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(test_generator.classes, predIdxs,\n",
    "\ttarget_names=test_generator.class_indices.keys()))\n",
    "print(confusion_matrix(test_generator.classes, predIdxs))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Task2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
